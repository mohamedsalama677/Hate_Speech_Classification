{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySsIPBRiorxK"
      },
      "source": [
        "**Dataset**\n",
        "labeled datasset collected from twitter (Lab 1 - Hate Speech.tsv)\n",
        "\n",
        "**Objective**\n",
        "classify tweets containing hate speech from other tweets. <br>\n",
        "0 -> no hate speech <br>\n",
        "1 -> contains hate speech <br>\n",
        "\n",
        "\n",
        "**Evaluation metric**\n",
        "macro f1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-6lrKz6orxT"
      },
      "source": [
        "### Import used libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXUPo3g4orxV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import contractions\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import xgboost as xgb\n",
        "\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_colwidth', 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG8MkuvjorxX"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLI9k1rjXLOE"
      },
      "source": [
        "###### Note: search how to load the data from tsv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "BYeqhp66orxY",
        "outputId": "aff24c51-f37a-4150-c862-cb51c2a44f6c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 31535,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9238,\n        \"min\": 1,\n        \"max\": 31962,\n        \"num_unique_values\": 31535,\n        \"samples\": [\n          822,\n          16265,\n          8867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29130,\n        \"samples\": [\n          \"this obviously  #tcot gets on &amp; #inaspanof maybe #allof two seconds after boarding - thinks he \\\"knows\\\" what\\u00e2\\u0080\\u00a6 \",\n          \"the @user gave #words with #ibbleobble some #fabtastic feedback! we're really  ! \\u00e2\\u0080\\u00a6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-533aabbe-2f3a-4dd2-b644-afb9646f7219\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in urð±!!! ððððð¦ð¦ð¦</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before they leave. chaos and pay disputes when they get there. #allshowandnogo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @user @user @user @user dannyâ¦</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð¯ can't think about that ð­ #school #exams   #hate #imagine #actorslife #revolutionschool #girl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers  â¦</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-533aabbe-2f3a-4dd2-b644-afb9646f7219')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-533aabbe-2f3a-4dd2-b644-afb9646f7219 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-533aabbe-2f3a-4dd2-b644-afb9646f7219');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35531a96-5a8f-417a-bdd5-84d35c783ba1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35531a96-5a8f-417a-bdd5-84d35c783ba1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35531a96-5a8f-417a-bdd5-84d35c783ba1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    label  \\\n",
              "id          \n",
              "1       0   \n",
              "2       0   \n",
              "3       0   \n",
              "4       0   \n",
              "5       0   \n",
              "6       0   \n",
              "7       0   \n",
              "8       0   \n",
              "9       0   \n",
              "10      0   \n",
              "\n",
              "                                                                                                                                              tweet  \n",
              "id                                                                                                                                                   \n",
              "1                                             @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run  \n",
              "2                        @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
              "3                                                                                                                               bihday your majesty  \n",
              "4                                                              #model   i love u take with u all the time in urð±!!! ðððð\n",
              "ð¦ð¦ð¦  \n",
              "5                                                                                                            factsguide: society now    #motivation  \n",
              "6                                [2/2] huge fan fare and big talking before they leave. chaos and pay disputes when they get there. #allshowandnogo  \n",
              "7                                                                         @user camping tomorrow @user @user @user @user @user @user @user dannyâ¦  \n",
              "8   the next school year is the year for exams.ð¯ can't think about that ð­ #school #exams   #hate #imagine #actorslife #revolutionschool #girl  \n",
              "9                                                            we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers  â¦  \n",
              "10                                                                                                 @user @user welcome here !  i'm   it's so #gr8 !  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/Hate Speech.tsv\", sep= \"\\t\", index_col='id')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wgmWgZMSaoey"
      },
      "outputs": [],
      "source": [
        "# a helper functions and imports\n",
        "from IPython.display import display\n",
        "def highlight_col(x, df):\n",
        "    #set by condition\n",
        "    mask =  df['label'] == 'pos'\n",
        "    mask2 = df['label'] == 'neg'\n",
        "    x = pd.DataFrame('', index=df.index, columns=df.columns)\n",
        "    x.loc[mask] = 'background-color: #e6ffe6'\n",
        "    x.loc[mask2] = 'background-color: #ffe6e6'\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "lvmwRvXMXLOF",
        "outputId": "9762ab3d-6921-4cde-af2f-d328a7a6cb20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>31535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweet</th>\n",
              "      <td>31535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label    31535\n",
              "tweet    31535\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_3dKD5BXLOF"
      },
      "source": [
        "### Data splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-3qZx87XLOF"
      },
      "source": [
        "It is a good practice to split the data before EDA helps maintain the integrity of the machine learning process, prevents data leakage, simulates real-world scenarios more accurately, and ensures reliable model performance evaluation on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oSDVI7U9XLOG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUjeXNJ5ZPXZ",
        "outputId": "bec97bf6-eed1-462e-f986-e6e2a92bf263"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(31535, 2)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8sE2tFGkYRwa"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(df, test_size=0.2, random_state=1234)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cmZsAgeu6So-"
      },
      "outputs": [],
      "source": [
        "# Split the train into valdtion and train\n",
        "X_train, X_val, y_train, y_val = train_test_split(train['tweet'], train['label'], test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "izjNbKA36boG"
      },
      "outputs": [],
      "source": [
        "# Now, process the test data\n",
        "X_test = test['tweet']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqWVKi_GorxZ"
      },
      "source": [
        "### EDA on training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1zxJpFxorxa"
      },
      "source": [
        "- check NaNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "HVEttSujorxa",
        "outputId": "2fc69df7-d862-4627-b3d8-913045d9607a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweet</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label    0\n",
              "tweet    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwjbzVaIorxb"
      },
      "source": [
        "- check duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_FlBWISorxb",
        "outputId": "b413061d-977c-4047-9678-5c21d50181fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1835"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjIBFc35orxc"
      },
      "source": [
        "- show a representative sample of data texts to find out required preprocessing steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "zGFKzSCRorxc",
        "outputId": "ddd1fc22-3652-4a40-c1bb-1f0d02742526"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_b59b7\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_b59b7_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
              "      <th id=\"T_b59b7_level0_col1\" class=\"col_heading level0 col1\" >tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >id</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row0\" class=\"row_heading level0 row0\" >5670</th>\n",
              "      <td id=\"T_b59b7_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_b59b7_row0_col1\" class=\"data row0 col1\" >everyday life for a white south african.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row1\" class=\"row_heading level0 row1\" >10008</th>\n",
              "      <td id=\"T_b59b7_row1_col0\" class=\"data row1 col0\" >0</td>\n",
              "      <td id=\"T_b59b7_row1_col1\" class=\"data row1 col1\" >@user always seems a shame to build something so nice then box it back down again. good to see you all again</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row2\" class=\"row_heading level0 row2\" >31182</th>\n",
              "      <td id=\"T_b59b7_row2_col0\" class=\"data row2 col0\" >0</td>\n",
              "      <td id=\"T_b59b7_row2_col1\" class=\"data row2 col1\" >@user @user @user you want to see   ?  this is sad  #obama is destroying america from within</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row3\" class=\"row_heading level0 row3\" >23020</th>\n",
              "      <td id=\"T_b59b7_row3_col0\" class=\"data row3 col0\" >0</td>\n",
              "      <td id=\"T_b59b7_row3_col1\" class=\"data row3 col1\" >some people bore me...but im all smiles   vibes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row4\" class=\"row_heading level0 row4\" >25501</th>\n",
              "      <td id=\"T_b59b7_row4_col0\" class=\"data row4 col0\" >0</td>\n",
              "      <td id=\"T_b59b7_row4_col1\" class=\"data row4 col1\" >7 impoant things to allow the #child to be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row5\" class=\"row_heading level0 row5\" >28379</th>\n",
              "      <td id=\"T_b59b7_row5_col0\" class=\"data row5 col0\" >0</td>\n",
              "      <td id=\"T_b59b7_row5_col1\" class=\"data row5 col1\" >@user having day/night ashes test is disgraceful! sacrilege changing a format that doesn't need changing! what about tradition?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row6\" class=\"row_heading level0 row6\" >19528</th>\n",
              "      <td id=\"T_b59b7_row6_col0\" class=\"data row6 col0\" >0</td>\n",
              "      <td id=\"T_b59b7_row6_col1\" class=\"data row6 col1\" >@user @user @user @user @user still blaming harper you guys? all of you need professional help. #wow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row7\" class=\"row_heading level0 row7\" >13805</th>\n",
              "      <td id=\"T_b59b7_row7_col0\" class=\"data row7 col0\" >0</td>\n",
              "      <td id=\"T_b59b7_row7_col1\" class=\"data row7 col1\" >have a great day! #saturday #shopping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row8\" class=\"row_heading level0 row8\" >26716</th>\n",
              "      <td id=\"T_b59b7_row8_col0\" class=\"data row8 col0\" >0</td>\n",
              "      <td id=\"T_b59b7_row8_col1\" class=\"data row8 col1\" >#justinb   gorilla simulator: you need to do to adapt to the environment. the need to tear the city. materia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b59b7_level0_row9\" class=\"row_heading level0 row9\" >4072</th>\n",
              "      <td id=\"T_b59b7_row9_col0\" class=\"data row9 col0\" >0</td>\n",
              "      <td id=\"T_b59b7_row9_col1\" class=\"data row9 col1\" >yes, i am saying that #hillaryclinton's major qualification is that she is female. sorry folks, deal with it.   i find nothing else.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ae1ebb3fc10>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', 100000)\n",
        "df_tmp = df.sample(10)\n",
        "df_tmp.style.apply(lambda x: highlight_col(x, df_tmp), axis=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqdSUtbdorxd"
      },
      "source": [
        "- check dataset balancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "JBHrSvXhorxd",
        "outputId": "2c0fda76-5998-4f82-9185-26fae4c299ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0    29322\n",
              "1     2213\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label= df['label'].value_counts()\n",
        "label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH0Sfo1YbXzW"
      },
      "source": [
        "There is unbalance in label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3wl_crkorxd"
      },
      "source": [
        "- Cleaning and Preprocessing are:\n",
        "    - 1\n",
        "    - 2\n",
        "    - 3\n",
        "    - ... etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyJkqK9gorxe"
      },
      "source": [
        "### Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8_K7EsfeaR1",
        "outputId": "9046e505-f2a3-4a78-a9fa-678c8cd3daf8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DZW2Bk6BbPqv"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # remove the tab and newline\n",
        "    text = text.replace('\\n', '').replace('\\t', ' ')\n",
        "\n",
        "    # remove extra white space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # remove contractions\n",
        "    text = contractions.fix(text)\n",
        "\n",
        "    # remove the punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "\n",
        "    # Remove email addresses\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # remove emojis\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "\n",
        "    # remove text elongation\n",
        "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    custom_stopwords = {'also', 'would', 'could', 'may', 'might', 'must', 'need'}\n",
        "    stop_words.update(custom_stopwords)\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "USBEQIwZparr"
      },
      "outputs": [],
      "source": [
        "# Compute document vectors by averaging word vectors\n",
        "def document_vector(doc,model):\n",
        "    words = [word for word in doc if word in model.wv]\n",
        "    if words:\n",
        "        return np.mean(model.wv[words], axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOZnixyO6KwO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfzlkkuCbQBI",
        "outputId": "2da3b580-e0f8-46de-e4d5-48bdf99b3955"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# apply the preprocessing function\n",
        "X_train_tokens = [preprocess_text(doc) for doc in X_train]\n",
        "X_val_tokens = [preprocess_text(doc) for doc in X_val]\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(\n",
        "    vector_size=100,\n",
        "    min_count=1,\n",
        "    workers=4,\n",
        "    sg=0\n",
        ")\n",
        "\n",
        "model.build_vocab(X_train_tokens)\n",
        "model.train(X_train_tokens, total_examples=len(X_train_tokens), epochs=model.epochs)\n",
        "\n",
        "# Transform the documents into vectors\n",
        "X_train_vectors = np.array([document_vector(doc, model) for doc in X_train_tokens])\n",
        "X_val_vectors = np.array([document_vector(doc, model) for doc in X_val_tokens])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3q5usex5ydU"
      },
      "source": [
        "#### Oversampling and Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8gE3it13ReN",
        "outputId": "dcd0472e-5028-4dd2-a90b-07d07c637fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on valdtion: 0.9453032104637337\n",
            "Validation Macro F1 Score on Valdtion: 0.6264099196538937\n"
          ]
        }
      ],
      "source": [
        "# Train a RandomForest model\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=1234,class_weight='balanced')\n",
        "rf_clf.fit(X_train_vectors, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_val = rf_clf.predict(X_val_vectors)\n",
        "print(\"Accuracy on valdtion:\", accuracy_score(y_val, y_pred_val))\n",
        "print(\"Validation Macro F1 Score on Valdtion:\", f1_score(y_val, y_pred_val, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJOX24DA5izO",
        "outputId": "74dbcd2f-1084-42e9-9feb-75029c34c9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on Valdtion:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      4723\n",
            "           1       0.89      0.17      0.28       323\n",
            "\n",
            "    accuracy                           0.95      5046\n",
            "   macro avg       0.92      0.58      0.63      5046\n",
            "weighted avg       0.94      0.95      0.93      5046\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Report on Valdtion:\\n\", classification_report(y_val, y_pred_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDlfFl0j59Kp"
      },
      "source": [
        "#### Evaluate on Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXzIe0_k0g0U",
        "outputId": "4104cd57-e290-411b-c143-1ee1ef0d4c3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9416521325511337\n",
            "Validation Macro F1 Score on test: 0.6108372467984703\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the test data\n",
        "X_test_tokens = [preprocess_text(doc) for doc in X_test]\n",
        "\n",
        "# Transform the test documents into vectors\n",
        "X_test_vectors = np.array([document_vector(doc, model) for doc in X_test_tokens])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_test_pred = rf_clf.predict(X_test_vectors)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Validation Macro F1 Score on test:\", f1_score(y_test, y_test_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWiljbjb5qtK",
        "outputId": "33a822b1-9220-47cc-8e2a-107fbf497a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Classification Report on test:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      5880\n",
            "           1       0.95      0.15      0.25       427\n",
            "\n",
            "    accuracy                           0.94      6307\n",
            "   macro avg       0.95      0.57      0.61      6307\n",
            "weighted avg       0.94      0.94      0.92      6307\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Classification Report on test:\\n\", classification_report(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TauRMp57XLOI",
        "tags": []
      },
      "source": [
        "#### Extra: use custom scikit-learn Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94kstif8XLOI"
      },
      "source": [
        "Using custom transformers in scikit-learn provides flexibility, reusability, and control over the data transformation process, allowing you to seamlessly integrate with scikit-learn's pipelines, enabling you to combine multiple preprocessing steps and modeling into a single workflow. This makes your code more modular, readable, and easier to maintain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6q09kWyXLOI",
        "tags": []
      },
      "source": [
        "##### link: https://www.andrewvillazon.com/custom-scikit-learn-transformers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyrdIKSqXLOI"
      },
      "source": [
        "#### Example usage:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2AuYV7RvWbf"
      },
      "source": [
        "**Evaluation metric:**\n",
        "macro f1 score\n",
        "\n",
        "Macro F1 score is a useful metric in scenarios where you want to evaluate the overall performance of a multi-class classification model, **particularly when the classes are imbalanced**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey9r2y2pvX6K"
      },
      "source": [
        "![Calculation](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/639c3d934e82c1195cdf3c60_macro-f1.webp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u2EYQvrBorxf"
      },
      "outputs": [],
      "source": [
        "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass  # No need to initialize Word2Vec parameters here\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        if pd.isna(text):\n",
        "            return \"\"\n",
        "\n",
        "        # Lowercase the text\n",
        "        text = str(text).lower()\n",
        "\n",
        "        # Remove tabs, newlines, extra whitespace, contractions, and punctuation\n",
        "        text = text.replace('\\n', '').replace('\\t', ' ')\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = contractions.fix(text)\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "        # Remove URLs, emails, special characters, numbers, emojis, and elongation\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "        text = re.sub(r'\\S+@\\S+', '', text)\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "        text = re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "        # Tokenization and stopword removal\n",
        "        tokens = word_tokenize(text)\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        custom_stopwords = {'also', 'would', 'could', 'may', 'might', 'must', 'need'}\n",
        "        stop_words.update(custom_stopwords)\n",
        "\n",
        "        # Lemmatization\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "        return tokens\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [self.preprocess_text(doc) for doc in X]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tTSzuyxXXLOJ"
      },
      "outputs": [],
      "source": [
        "class Vectorizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, vector_size=100, min_count=1, workers=4, sg=0):\n",
        "        self.vector_size = vector_size\n",
        "        self.min_count = min_count\n",
        "        self.workers = workers\n",
        "        self.sg = sg\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Train the Word2Vec model\n",
        "        self.model = Word2Vec(\n",
        "            vector_size=self.vector_size,\n",
        "            min_count=self.min_count,\n",
        "            workers=self.workers,\n",
        "            sg=self.sg\n",
        "        )\n",
        "\n",
        "        # Build vocab and train model\n",
        "        self.model.build_vocab(X)\n",
        "        self.model.train(X, total_examples=len(X), epochs=self.model.epochs)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Compute document vectors\n",
        "        def document_vector(doc):\n",
        "            words = [word for word in doc if word in self.model.wv]\n",
        "            if words:\n",
        "                return np.mean(self.model.wv[words], axis=0)\n",
        "            else:\n",
        "                return np.zeros(self.vector_size)\n",
        "\n",
        "        return np.array([document_vector(doc) for doc in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "irwyR3D_6iVq"
      },
      "outputs": [],
      "source": [
        "class TfidfDocumentVectorizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, max_features=5000, min_df=2, max_df=0.85, ngram_range=(1, 1)):\n",
        "        self.max_features = max_features\n",
        "        self.min_df = min_df\n",
        "        self.max_df = max_df\n",
        "        self.ngram_range = ngram_range\n",
        "        self.vectorizer = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Convert list of token lists to list of strings for TfidfVectorizer\n",
        "        docs = [' '.join(doc) for doc in X]\n",
        "\n",
        "        # Initialize and fit the TF-IDF vectorizer\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=self.max_features,\n",
        "            min_df=self.min_df,\n",
        "            max_df=self.max_df,\n",
        "            ngram_range=self.ngram_range\n",
        "        )\n",
        "        self.vectorizer.fit(docs)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Convert list of token lists to list of strings\n",
        "        docs = [' '.join(doc) for doc in X]\n",
        "\n",
        "        # Transform documents to TF-IDF vectors\n",
        "        tfidf_matrix = self.vectorizer.transform(docs)\n",
        "\n",
        "        # Return as dense array for compatibility with other code\n",
        "        return tfidf_matrix.toarray()\n",
        "\n",
        "    def get_feature_names(self):\n",
        "        \"\"\"Return feature names (vocabulary terms)\"\"\"\n",
        "        if self.vectorizer is not None:\n",
        "            return self.vectorizer.get_feature_names_out()\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba0r1ASHorxf"
      },
      "source": [
        "**You  are doing Great so far!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9BhRQbYorxf"
      },
      "source": [
        "### Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au1FYDPzorxg"
      },
      "source": [
        "#### Extra: use scikit-learn pipline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofqFCLdrXLOJ"
      },
      "source": [
        "##### link: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5POyvNOXLOK"
      },
      "source": [
        "Using pipelines in scikit-learn promotes better code organization, reproducibility, and efficiency in machine learning workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FZzmborxg"
      },
      "source": [
        "#### Example usage:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYuw06cDN3ng"
      },
      "source": [
        "### 1- Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "PLfCaT4ZXLOK",
        "outputId": "12fe2834-92aa-4f13-f375-cf8914b4ae2f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;, CustomTransformer()),\n",
              "                                       (&#x27;vectorizing&#x27;,\n",
              "                                        TfidfDocumentVectorizer()),\n",
              "                                       (&#x27;model&#x27;,\n",
              "                                        LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                                           random_state=1234))]),\n",
              "             n_jobs=1,\n",
              "             param_grid={&#x27;model__C&#x27;: [0.1, 1, 10],\n",
              "                         &#x27;model__solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;],\n",
              "                         &#x27;vectorizing__max_features&#x27;: [500, 1000, 1500],\n",
              "                         &#x27;vectorizing__ngram_range&#x27;: [(1, 1), (1, 2)]},\n",
              "             scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;, average=macro))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;, CustomTransformer()),\n",
              "                                       (&#x27;vectorizing&#x27;,\n",
              "                                        TfidfDocumentVectorizer()),\n",
              "                                       (&#x27;model&#x27;,\n",
              "                                        LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
              "                                                           random_state=1234))]),\n",
              "             n_jobs=1,\n",
              "             param_grid={&#x27;model__C&#x27;: [0.1, 1, 10],\n",
              "                         &#x27;model__solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;],\n",
              "                         &#x27;vectorizing__max_features&#x27;: [500, 1000, 1500],\n",
              "                         &#x27;vectorizing__ngram_range&#x27;: [(1, 1), (1, 2)]},\n",
              "             scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;, average=macro))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;, CustomTransformer()),\n",
              "                (&#x27;vectorizing&#x27;, TfidfDocumentVectorizer(max_features=1500)),\n",
              "                (&#x27;model&#x27;,\n",
              "                 LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;,\n",
              "                                    random_state=1234, solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CustomTransformer</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>CustomTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfDocumentVectorizer</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfDocumentVectorizer(max_features=1500)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, random_state=1234,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('preprocessing', CustomTransformer()),\n",
              "                                       ('vectorizing',\n",
              "                                        TfidfDocumentVectorizer()),\n",
              "                                       ('model',\n",
              "                                        LogisticRegression(class_weight='balanced',\n",
              "                                                           random_state=1234))]),\n",
              "             n_jobs=1,\n",
              "             param_grid={'model__C': [0.1, 1, 10],\n",
              "                         'model__solver': ['liblinear', 'lbfgs'],\n",
              "                         'vectorizing__max_features': [500, 1000, 1500],\n",
              "                         'vectorizing__ngram_range': [(1, 1), (1, 2)]},\n",
              "             scoring=make_scorer(f1_score, response_method='predict', average=macro))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessing', CustomTransformer()),  # Preprocessing text\n",
        "    ('vectorizing', TfidfDocumentVectorizer()),  # Vectorizing using Word2Vec\n",
        "    ('model', LogisticRegression(random_state=1234,class_weight = 'balanced')),  # Logistic regression model\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'vectorizing__max_features': [500, 1000, 1500],  # Number of features to keep\n",
        "    'vectorizing__ngram_range': [(1, 1), (1, 2)],  # Unigrams only or unigrams and bigrams  # Minimum word count for Word2Vec\n",
        "    'model__C': [0.1, 1, 10],  # Regularization strength for Logistic Regression\n",
        "    'model__solver': ['liblinear', 'lbfgs'],  # Solvers for Logistic Regression\n",
        "}\n",
        "\n",
        "# Define the scoring metric\n",
        "scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=5, n_jobs=1)\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBqHWJzuLJ3f",
        "outputId": "c6993d26-56d2-47a9-d7a1-d83f9f0022b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'model__C': 10, 'model__solver': 'liblinear', 'vectorizing__max_features': 1500, 'vectorizing__ngram_range': (1, 1)}\n",
            "Best Macro F1 Score: 0.7110790739789471\n",
            "Test Macro F1 Score: 0.7027808440628176\n"
          ]
        }
      ],
      "source": [
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Macro F1 Score:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model to predict on the test set\n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "print(\"Test Macro F1 Score:\", f1_score(y_test, y_test_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89D6jJ5POSjw"
      },
      "source": [
        "### 2- RandomFroest Classifer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9EX-tT1LKFA",
        "outputId": "19ab9413-5902-4a05-c356-d97e2c2dc135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'vectorizing__max_features': 1500, 'vectorizing__ngram_range': (1, 1)}\n",
            "Best Macro F1 Score: 0.7434958035739372\n",
            "Test Macro F1 Score: 0.7362853593568641\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessing', CustomTransformer()),  # Preprocessing text\n",
        "    ('vectorizing', TfidfDocumentVectorizer()),  # Vectorizing using Word2Vec\n",
        "    ('model', RandomForestClassifier(random_state=1234,n_estimators=200,class_weight = 'balanced')),  # Random Forest model\n",
        "])\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'vectorizing__max_features': [500, 1000, 1500],  # Number of features to keep\n",
        "    'vectorizing__ngram_range': [(1, 1), (1, 2)],  # Unigrams only or unigrams and bigrams\n",
        "}\n",
        "\n",
        "# Define the scoring metric\n",
        "scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# Set up the grid search\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=5, n_jobs=1)\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Macro F1 Score:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model to predict on the test set\n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "print(\"Test Macro F1 Score:\", f1_score(y_test, y_test_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB7z0TlSnRcI"
      },
      "source": [
        "# 3- XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UHRoFBVnUeL",
        "outputId": "95e4afc4-3891-4a78-a69e-01198ce0c3b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:23:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:23:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:23:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:23:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:24:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:24:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:24:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:24:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:24:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:25:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:25:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:25:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:25:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:25:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:26:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:26:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:26:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:26:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:27:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:27:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:27:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:27:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:28:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:28:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:28:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:29:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:29:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:30:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:30:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:30:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'vectorizing__max_features': 1500, 'vectorizing__ngram_range': (1, 1)}\n",
            "Best Macro F1 Score: 0.7536158181901156\n",
            "Test Macro F1 Score: 0.7634027024788193\n"
          ]
        }
      ],
      "source": [
        "# Define the pipeline with XGBoost\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessing', CustomTransformer()),\n",
        "    ('vectorizing', TfidfDocumentVectorizer()),\n",
        "    ('model', xgb.XGBClassifier(random_state=1234,n_estimators=200,class_weight = 'balanced')),\n",
        "])\n",
        "# Define the parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'vectorizing__max_features': [500, 1000, 1500],  # Number of features to keep\n",
        "    'vectorizing__ngram_range': [(1, 1), (1, 2)],  # Unigrams only or unigrams and bigrams\n",
        "}\n",
        "\n",
        "# Define the scoring metric\n",
        "scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# Set up the grid search\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=5, n_jobs=1)\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Macro F1 Score:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model to predict on the test set\n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "print(\"Test Macro F1 Score:\", f1_score(y_test, y_test_pred, average='macro'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF5HkHYfeYfB"
      },
      "source": [
        "## 3- CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z29h-xoEh667",
        "outputId": "d2d8edf5-d507-4118-9fe6-161c73f60b77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2558\n",
            "Epoch 2/10\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.0982\n",
            "Epoch 3/10\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0582\n",
            "Epoch 4/10\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0354\n",
            "Epoch 5/10\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0210\n",
            "Epoch 6/10\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0136\n",
            "Epoch 7/10\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0065\n",
            "Epoch 8/10\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0056\n",
            "Epoch 9/10\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0025\n",
            "Epoch 10/10\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0050\n",
            "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Macro F1 Score: 0.8099913432050307\n"
          ]
        }
      ],
      "source": [
        "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return [text.lower() for text in X]\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Tokenizer & Padder With CNN\n",
        "# ------------------------------\n",
        "class TextCNNPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, max_features=10000, maxlen=100):\n",
        "        self.max_features = max_features\n",
        "        self.maxlen = maxlen\n",
        "        self.tokenizer = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.tokenizer = Tokenizer(num_words=self.max_features)\n",
        "        self.tokenizer.fit_on_texts(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        sequences = self.tokenizer.texts_to_sequences(X)\n",
        "        return pad_sequences(sequences, maxlen=self.maxlen)\n",
        "\n",
        "# ------------------------------\n",
        "# 3. CNN Model Function\n",
        "# ------------------------------\n",
        "def build_cnn_model(input_length, num_classes, max_features=10000, embedding_dims=50,\n",
        "                    filters=64, kernel_size=3, hidden_dims=50, dropout_rate=0.5):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=max_features, output_dim=embedding_dims, input_length=input_length))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(hidden_dims, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    if num_classes == 2:\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    else:\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "maxlen = 100\n",
        "\n",
        "# Step 1: Apply preprocessing pipeline\n",
        "preprocess_pipeline = Pipeline([\n",
        "    ('custom', CustomTransformer()),\n",
        "    ('token_pad', TextCNNPreprocessor(max_features=10000, maxlen=maxlen))\n",
        "])\n",
        "\n",
        "X_train_processed = preprocess_pipeline.fit_transform(X_train, y_train)\n",
        "X_test_processed = preprocess_pipeline.transform(X_test)\n",
        "\n",
        "# Step 2: Build & train the model\n",
        "model = build_cnn_model(input_length=maxlen, num_classes=num_classes)\n",
        "model.fit(X_train_processed, np.array(y_train), epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Step 3: Predict & Evaluate\n",
        "y_pred_probs = model.predict(X_test_processed)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten() if num_classes == 2 else np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"Macro F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpfFAjvFXLOM"
      },
      "source": [
        "### Conclusion and final results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouR2Oaumv_eU"
      },
      "source": [
        "1- After try the Embedding technics I found that tfidif is the best one of them in this task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jQ2xHPwvsfO"
      },
      "source": [
        "2- After training Logisitic regression, Random Forest, XGboost and CNN model I found That CNN is the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxPbVBAtXLOM",
        "outputId": "1569dc6c-5d7e-436a-d207-2eb14ff7dd03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Macro F1 Score for CNN: 0.8099913432050307\n"
          ]
        }
      ],
      "source": [
        "y_pred_probs = model.predict(X_test_processed)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten() if num_classes == 2 else np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"Macro F1 Score for CNN:\", f1_score(y_test, y_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3uWM55ZXLOM",
        "outputId": "b9b121a9-0a74-4cc2-fce0-4cd06b9dbe94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"cnn_text_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw1GVnYLorxi"
      },
      "source": [
        "#### Done!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
